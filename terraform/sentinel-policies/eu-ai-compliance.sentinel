# EU AI Act Compliance Policy
# Enforces requirements for high-risk AI systems under EU AI Act
# Ensures proper documentation, risk assessment, and human oversight

import "tfplan/v2" as tfplan
import "strings"

# Parameters - High-risk AI categories per EU AI Act
param high_risk_systems default [
  "biometric-identification",
  "critical-infrastructure",
  "education-scoring",
  "employment-screening", 
  "credit-scoring",
  "law-enforcement",
  "migration-control"
]

param required_documentation default [
  "risk-assessment",
  "human-oversight-plan",
  "accuracy-metrics",
  "bias-testing",
  "transparency-notice"
]

# Check if resource is deploying a high-risk AI system
is_high_risk_ai = func(rc) {
  tags = rc.change.after.tags else {}
  ai_category = tags["ai-category"] else ""
  ai_use_case = tags["ai-use-case"] else ""
  
  # Check if it's a high-risk category
  return ai_category in high_risk_systems or
         strings.contains(ai_use_case, "facial-recognition") or
         strings.contains(ai_use_case, "biometric") or
         strings.contains(ai_use_case, "credit-decision") or
         strings.contains(ai_use_case, "employment") or
         strings.contains(ai_use_case, "education-assessment")
}

# Verify EU AI Act documentation exists
check_ai_documentation = func(rc) {
  tags = rc.change.after.tags else {}
  
  # All required documents must be referenced
  all required_documentation as doc {
    doc_tag = "eu-ai-act-" + doc
    tags contains doc_tag and tags[doc_tag] != ""
  }
}

# Check human oversight requirements
check_human_oversight = func(rc) {
  tags = rc.change.after.tags else {}
  
  # Must have human-in-the-loop or human-on-the-loop
  human_oversight = tags["human-oversight-type"] else ""
  
  return human_oversight in ["human-in-the-loop", "human-on-the-loop", "human-in-command"] and
         tags["human-oversight-sla"] != "" and
         tags["override-mechanism"] == "enabled"
}

# Check transparency requirements
check_transparency = func(rc) {
  tags = rc.change.after.tags else {}
  
  # Must inform users they're interacting with AI
  return tags["ai-disclosure"] == "enabled" and
         tags["explainability-method"] != "" and
         tags["contestation-mechanism"] == "enabled"
}

# Check bias and fairness testing
check_bias_testing = func(rc) {
  tags = rc.change.after.tags else {}
  
  return tags["bias-testing-date"] != "" and
         tags["fairness-metrics"] != "" and
         tags["demographic-parity"] != ""
}

# Main compliance rule for high-risk AI
eu_ai_act_compliance = rule {
  all tfplan.resource_changes as _, rc {
    # Only check ML/AI resources
    rc.type not in [
      "aws_sagemaker_endpoint",
      "aws_sagemaker_model",
      "azurerm_machine_learning_inference_cluster",
      "google_vertex_ai_endpoint",
      "aws_lambda_function",
      "azurerm_container_instance"
    ] or
    
    # If not high-risk, no special requirements
    not is_high_risk_ai(rc) or
    
    # If high-risk, must meet all requirements
    (check_ai_documentation(rc) and
     check_human_oversight(rc) and
     check_transparency(rc) and
     check_bias_testing(rc))
  }
}

# Additional check for prohibited AI uses
prohibited_ai_check = rule {
  all tfplan.resource_changes as _, rc {
    tags = rc.change.after.tags else {}
    ai_use_case = tags["ai-use-case"] else ""
    
    # Prohibited uses under EU AI Act
    not strings.contains(ai_use_case, "social-scoring") and
    not strings.contains(ai_use_case, "subliminal-manipulation") and
    not strings.contains(ai_use_case, "exploitative-vulnerable-groups") and
    not strings.contains(ai_use_case, "real-time-biometric-public-spaces")
  }
}

# Check for conformity assessment
conformity_assessment = rule {
  all tfplan.resource_changes as _, rc {
    tags = rc.change.after.tags else {}
    
    # If high-risk, needs conformity assessment
    not is_high_risk_ai(rc) or
    (tags["ce-marking"] == "pending" or tags["ce-marking"] == "approved") and
    tags["notified-body-id"] != ""
  }
}

# Main rule combining all EU AI Act checks
main = rule {
  eu_ai_act_compliance and prohibited_ai_check and conformity_assessment
} else {
  "EU AI Act Compliance Failed: High-risk AI systems require: " +
  "1) Complete risk assessment and documentation " +
  "2) Human oversight mechanism " +
  "3) Transparency and explainability features " +
  "4) Bias testing and fairness metrics " +
  "5) Conformity assessment for CE marking. " +
  "Prohibited: social scoring, subliminal manipulation, exploitative systems."
}